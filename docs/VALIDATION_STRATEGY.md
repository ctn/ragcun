# Validation Strategy: 3-Tier Approach

Before committing to expensive full training, validate your approach in stages.

## üéØ Quick Overview

| Stage | Time | Cost | What You Learn |
|-------|------|------|----------------|
| **0. Diagnostic** | 5 min | Free | Implementation works correctly |
| **1. Smoke Test** | 1-2 hours | Free | Isotropy helps retrieval |
| **2. Pilot Run** | 1-2 days | Free | Ready for publication |
| **3. Full Training** | 15 days or $220 | Variable | Publication-quality results |

---

## Stage 0: Quick Diagnostic (5 minutes) ‚ö°

**Goal:** Verify implementation is correct

```bash
python scripts/diagnostic_quick.py
```

**What it checks:**
- ‚úÖ Model loads and runs
- ‚úÖ Loss functions compute correctly
- ‚úÖ Lambda affects training
- ‚úÖ Isotropy improves with regularization (10 gradient steps)

**Output:**
```
‚úÖ ALL CHECKS PASSED!

Your implementation is correct:
  ‚úì Model works
  ‚úì Losses compute correctly  
  ‚úì Lambda affects training
  ‚úì Isotropy improves (+0.0342)

‚Üí Ready to train!
```

**Decision:**
- ‚úÖ All pass ‚Üí Proceed to Stage 1
- ‚ùå Any fail ‚Üí Debug before training

---

## Stage 1: Smoke Test (1-2 hours) üî¨

**Goal:** Prove isotropy helps retrieval with meaningful data

```bash
./scripts/train_smoke_test.sh
```

**What it does:**
- Trains on 10K MS MARCO examples (1 epoch)
- Compares baseline vs. isotropy
- Measures isotropy scores directly
- Tests retrieval accuracy

**Output:**
```
ISOTROPY SCORES (higher = better)
  Baseline:   0.7234
  Isotropy:   0.8891
  Improvement: +0.1657 ‚úÖ

RETRIEVAL ACCURACY (500 queries)
  Baseline Acc@1: 32.1%
  Isotropy Acc@1: 35.8%
  Œî: +3.7% ‚úÖ

‚úÖ SUCCESS: Isotropy helps!
```

**Decision:**
- ‚úÖ Isotropy & retrieval improve ‚Üí Proceed to Stage 2
- ‚ö†Ô∏è  Mixed results ‚Üí Tune hyperparameters, re-run
- ‚ùå No improvement ‚Üí Debug before Stage 2

---

## Stage 2: Pilot Run (1-2 days) üß™

**Goal:** Validate approach with enough data to predict full results

```bash
./scripts/train_pilot.sh
```

**What it does:**
- Trains on 50K MS MARCO examples (2 epochs)
- Evaluates on 3 representative BEIR datasets
- Predicts full training results

**Output:**
```
Quick Results (on 3 BEIR datasets):
  Baseline: 46.2% NDCG@10
  Isotropy: 47.9% NDCG@10
  Improvement: +1.7% ‚úÖ

‚úÖ Isotropy is helping! Ready for full training.
```

**Decision:**
- ‚úÖ >0.5% improvement ‚Üí Proceed to full training
- ‚ö†Ô∏è  <0.5% improvement ‚Üí Check logs, consider tuning
- ‚ùå No improvement ‚Üí Review approach

---

## Stage 3: Full Training üöÄ

**Goal:** Publication-quality results

### Option A: Local (Free, Slow)
```bash
./scripts/train_publication_recommended.sh
./scripts/evaluate_all_beir.sh
```
- **Time:** 15 days
- **Cost:** Free
- **Result:** All 3 models + full BEIR evaluation

### Option B: AWS p4d (Fast, $$)
```bash
# On p4d.24xlarge
./scripts/train_parallel_p4d.sh
```
- **Time:** ~21 hours
- **Cost:** ~$220
- **Result:** All 3 models + full BEIR evaluation

---

## üìä What Each Stage Proves

| Stage | Proves | Key Metrics |
|-------|--------|-------------|
| 0. Diagnostic | Implementation correct | Isotropy Œî > 0.01 |
| 1. Smoke Test | Isotropy helps | Retrieval Œî > 2% |
| 2. Pilot Run | Predicts full results | BEIR Œî > 0.5% |
| 3. Full Training | Publication quality | BEIR > 49%, 15 datasets |

---

## üéì Recommended Path

### For Research/Publication:
1. **Diagnostic** (5 min) - Verify implementation
2. **Smoke Test** (2 hours) - Quick proof of concept
3. **Pilot Run** (2 days) - Validate on meaningful data
4. **AWS p4d** (1 day) - Fast publication results

**Total time:** ~3 days from start to publication-ready results

### For Experimentation:
1. **Diagnostic** (5 min) - Verify implementation
2. **Smoke Test** (2 hours) - Test ideas quickly
3. Iterate on hyperparameters
4. **Pilot Run** when confident

### For Patience/Free Compute:
1. **Diagnostic** (5 min)
2. **Local Full Training** (15 days) - Set and forget

---

## üí° Pro Tips

**Save time:**
- Always run Diagnostic first (catches bugs early)
- Smoke Test is fast enough to iterate on hyperparameters
- Pilot Run predicts full results well

**Save money:**
- Validate locally before AWS
- AWS spot instances can interrupt - use snapshots!
- Smoke Test + Pilot = high confidence for AWS

**For publication:**
- All 3 stages provide complementary evidence:
  - Diagnostic: Implementation is sound
  - Smoke: Core mechanism works
  - Pilot: Scales to real data
  - Full: Publication-quality evaluation

---

## üö¶ Current Status

After pre-flight tests passed, you're at:
```
[ ] Stage 0: Diagnostic
[ ] Stage 1: Smoke Test  
[ ] Stage 2: Pilot Run
[ ] Stage 3: Full Training
```

**Next command:**
```bash
# Start with diagnostic (5 min)
python scripts/diagnostic_quick.py
```

If it passes, you'll know your implementation is correct and can confidently proceed to training stages!

