{
  "project_context": {
    "goal": "Validate LeJEPA isotropy regularization for improving retrieval model performance on text embeddings",
    "innovation": [
      "Apply isotropy regularization (from LeJEPA vision paper) to text retrieval",
      "Use Gaussian embeddings (unnormalized) with Euclidean distance",
      "Compare against vanilla baseline (cosine similarity on raw model)"
    ],
    "base_model": "sentence-transformers/all-mpnet-base-v2",
    "model_size": "110M parameters",
    "architecture": "Base encoder (frozen or fine-tuned) + projection layer (768\u2192512)"
  },
  "experimental_setup": {
    "training_data": {
      "small": "10,000 MS MARCO examples (smoke tests)",
      "medium": "48,433 MS MARCO examples (current main experiment)",
      "full": "502,939 MS MARCO examples (not used yet)"
    },
    "evaluation_benchmarks": {
      "in_domain": "MS MARCO Dev Set (1,939 queries)",
      "zero_shot": {
        "benchmark": "BEIR",
        "datasets": [
          "SciFact",
          "NFCorpus",
          "ArguAna",
          "FiQA",
          "TREC-COVID"
        ]
      }
    },
    "training_strategies": [
      "Vanilla Baseline: Raw MPNet, no training, cosine similarity",
      "Baseline: Full fine-tune, no isotropy (\u03bb_iso=0)",
      "Full FT+Iso: Full fine-tune with isotropy (\u03bb_iso=1.0)",
      "Frozen+Iso: Frozen base + train projection with isotropy"
    ]
  },
  "key_findings": {
    "from_10k_experiments": {
      "vanilla_untrained": "NDCG@10 \u2248 0.49 (estimated)",
      "baseline_trained_no_iso": "NDCG@10 = 0.095 (catastrophic forgetting!)",
      "full_ft_iso": "NDCG@10 = 0.098 (still poor)",
      "frozen_iso": "NDCG@10 = 0.455 (almost recovers vanilla performance)"
    },
    "key_insight": "Full fine-tuning destroys zero-shot generalization! Frozen base + isotropy preserves it while adding task-specific learning."
  },
  "current_running_jobs": [
    {
      "job_id": 1,
      "name": "Training Frozen+Iso with 48K MS MARCO",
      "script": "scripts/train_frozen_48k.sh",
      "log_file": "logs/frozen_48k_mpnet_training.log",
      "model_path": "checkpoints/frozen_48k/mpnet_frozen_isotropy/",
      "status": "Epoch 2 of 3, ~73% complete (step 2213/3028)",
      "loss": "~1.07 (stable)",
      "eta_minutes": 100,
      "goal": "See if more training data (48K vs 10K) helps beat vanilla baseline"
    },
    {
      "job_id": 2,
      "name": "Evaluating Vanilla Baseline on BEIR",
      "script": "scripts/eval_vanilla_baseline.py",
      "log_file": "logs/vanilla_baseline_eval.log",
      "output_file": "results/beir_standard/vanilla_mpnet.json",
      "model": "Raw sentence-transformers/all-mpnet-base-v2 (no training)",
      "method": "Cosine similarity (standard sentence-transformers)",
      "status": "Dataset 5/5 (TREC-COVID), encoding corpus 7% (187/2678 batches)",
      "eta_hours": "3-4",
      "completed_results": {
        "scifact": "NDCG@10 = 0.6557",
        "nfcorpus": "NDCG@10 = 0.3337",
        "arguana": "NDCG@10 = 0.3622",
        "fiqa": "completed, result not extracted yet",
        "trec_covid": "in progress, 7% encoded"
      },
      "purpose": "Establish true baseline for comparison"
    },
    {
      "job_id": 3,
      "name": "Evaluating Frozen+Iso 48K (Epoch 1 Checkpoint) on BEIR",
      "script": "scripts/evaluate_beir.py",
      "log_file": "logs/frozen_48k_epoch1_beir_eval.log",
      "output_file": "results/beir_standard/frozen_48k_epoch1.json",
      "model_path": "checkpoints/frozen_48k/mpnet_frozen_isotropy/checkpoint_epoch_1.pt",
      "status": "Dataset 2/5 (FiQA), encoding corpus 14% (124/901 batches)",
      "eta_hours": "2-3",
      "purpose": "Early feedback - is 1 epoch enough, or do we need all 3?"
    }
  ],
  "file_structure": {
    "checkpoints": "checkpoints/frozen_48k/ - Main training output",
    "results": "results/beir_standard/ - BEIR evaluation results (JSON)",
    "logs": "logs/ - Training and evaluation logs",
    "scripts": "scripts/ - All training/evaluation scripts",
    "core_code": "ragcun/ - Core model code (GaussianEmbeddingGemma)"
  },
  "architecture": {
    "base_encoder": {
      "model": "sentence-transformers/all-mpnet-base-v2",
      "output_dim": 768,
      "normalization": "normalize_embeddings=True (may be changed)"
    },
    "projection_layer": {
      "structure": "nn.Sequential(Linear(768, 512), GELU(), Dropout(0.1), Linear(512, 512))",
      "output_dim": 512
    },
    "output": "Unnormalized 512-dim Gaussian embeddings",
    "similarity": "Euclidean distance (not cosine)"
  },
  "loss_function": {
    "contrastive_loss": "Positive pairs closer, negatives farther",
    "isotropy_loss": "SIGReg: Encourages Cov(emb) \u2248 \u03c3\u00b2\u00b7I",
    "regularization": "\u03bb_iso=1.0, \u03bb_reg=0.1"
  },
  "next_steps": [
    "Evaluate Frozen+Iso 48K (Epoch 3, best_model.pt) on BEIR",
    "Compare all results: Vanilla baseline, Frozen+Iso 10K, Frozen+Iso 48K (1 epoch), Frozen+Iso 48K (3 epochs)",
    "Potential ablation: Remove normalization from base model (normalize_embeddings=False)",
    "If results are good: Scale to full MS MARCO (502K examples)"
  ],
  "known_issues": [
    "Normalization bottleneck: Base model outputs normalized to unit sphere before projection. May hurt isotropy optimization. Proposed fix: normalize_embeddings=False (requires retraining)",
    "TREC-COVID is very large (171K docs) and slow to evaluate - this is normal and expected",
    "All processes run in background (nohup) on AWS - safe to disconnect"
  ],
  "timestamp": "2025-11-16T06:33:29.426604"
}